{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 PCA and Logistic Regression to Classify Images \n",
    "\n",
    "### The task here is to classify images using a Logistic Regression model. \n",
    "### But the images are too high-dimensional for a logistic regression model to work.  \n",
    "### So, we will use PCA to perform dimensionality reduction first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold #this is new "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = loadmat('faces.mat')\n",
    "faces = f['faces'] #This are the faces.  There are 72 faces closely cropped to the boundary of the face.\n",
    "smiling = f['smiling'][0] #Flag to indicate if the face was a smile. 0 means neutral expression and 1 means smiling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visualize the average smiling and neutral face in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use PCA to decompose the face images into an underlying set of facial patterns (eigenvectors). \n",
    "### Use a line plot or bar plot to visualize the **score** values averaged for smiling and neutral faces,\n",
    "### Plot magnitude of the difference in scores between smiling and neutral. \n",
    "### Identify the 3 eigenvectors with the biggest magnitude difference between smiling and neutral faces (`np.argsort` is helpful), and plot an image of each of the corresponding eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Fit a logistic regression model to classify smiling faces versus neutral faces.  \n",
    "### To test your model lets do a straightforward k-fold cross validation. When doing k-fold lets use the StratifiedKFold method to make sure each fold is balanced (i.e., the ratio of the number of items in each of the classes is the same in training and test sets).  \n",
    "### As we have 72 images lets do 4-fold crossvalidation so it splits up nicely.  \n",
    "### How many eigenvectors (columns of score) do you want to include in the model? How do you think you should decide? (Hint: Examine the plots you made and justify a choice)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate model performance using the usual metrics.  Which eigenvectors were most informative?  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
